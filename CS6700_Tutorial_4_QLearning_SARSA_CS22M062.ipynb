{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.191806Z",
          "start_time": "2019-11-07T18:54:34.974648Z"
        },
        "id": "8X3sTfZFhbYv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvYEMz3_hbYw"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "In this section we will implement tabular SARSA and Q-learning algorithms for a grid world navigation task.\n",
        "\n",
        "## Environment details\n",
        "The agent can move from one grid coordinate to one of its adjacent grids using one of the four actions: UP, DOWN, LEFT and RIGHT. The goal is to go from a randomly assigned starting position to goal position.\n",
        "\n",
        "Actions that can result in taking the agent off the grid will not yield any effect.\n",
        "Lets look at the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.197212Z",
          "start_time": "2019-11-07T18:54:35.193559Z"
        },
        "id": "yeMXNQzohbYx"
      },
      "outputs": [],
      "source": [
        "DOWN = 0\n",
        "UP = 1\n",
        "LEFT = 2\n",
        "RIGHT = 3\n",
        "actions = [DOWN, UP, LEFT, RIGHT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77OIMbf9hbYx"
      },
      "source": [
        "Let us construct a grid in a text file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.313236Z",
          "start_time": "2019-11-07T18:54:35.198985Z"
        },
        "id": "dkltb2LjhbY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d67d911-9656-4434-a3ae-c96eaba07717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "1 1 1 1 1 1 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 1 1 1 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 1 1 1 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 1 1 1 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 1 1 1 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 1 1 1 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n"
          ]
        }
      ],
      "source": [
        "!cat grid_world2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqttG3_EhbY1"
      },
      "source": [
        "This is a $17\\times 23$ grid. The reward when an agent goes to a cell is negative of the value in that position in the text file (except if it is the goal cell). We will define the goal reward as 100. We will also fix the maximum episode length to 10000.\n",
        "\n",
        "Now let's make it more difficult. We add stochasticity to the environment: with probability 0.2 agent takes a random action (which can be other than the chosen action).\n",
        "There is also a westerly wind blowing (to the right). Hence, after every time-step, with probability 0.5 the agent also moves an extra step to the right.\n",
        "\n",
        "Now let's plot the grid world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.561594Z",
          "start_time": "2019-11-07T18:54:35.315669Z"
        },
        "id": "HiTa78PQhbY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "911855f2-0df3-4615-a260-f89060bb1149"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "world = 'grid_world2.txt'\n",
        "goal_reward = 100\n",
        "start_states = [(0,0), (0,20), (16,21)]\n",
        "goal_states=[(9,5)]\n",
        "max_steps=10000\n",
        "\n",
        "from grid_world import GridWorldEnv, GridWorldWindyEnv\n",
        "\n",
        "env = GridWorldEnv(world, goal_reward=goal_reward, start_states=start_states, goal_states=goal_states,\n",
        "                max_steps=max_steps, action_fail_prob=0.2)\n",
        "plt.figure(figsize=(10, 10))\n",
        "# Go UP\n",
        "env.step(UP)\n",
        "env.render(ax=plt, render_agent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlnJXdjZhbY2"
      },
      "source": [
        "### Legend\n",
        "- <span style=\"color:#0004FF\">*Blue*</span> is the **start state**.\n",
        "- <span style=\"color:#00FF23\">*Green*</span> is the **goal state**.\n",
        "- <span style=\"color:#F0FF00\">*Yellow*</span> is current **state of the agent**.\n",
        "- <span style=\"color:#FF2D00\">*Redness*</span> denotes the extent of **negative reward**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql6Pq_C5hbY3"
      },
      "source": [
        "### Q values\n",
        "We can use a 3D array to represent Q values. The first two indices are X, Y coordinates and last index is the action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.858103Z",
          "start_time": "2019-11-07T18:54:35.563178Z"
        },
        "scrolled": true,
        "id": "jNZ0pFB2hbY3"
      },
      "outputs": [],
      "source": [
        "from grid_world import plot_Q\n",
        "\n",
        "Q = np.zeros((env.grid.shape[0], env.grid.shape[1], len(env.action_space)))\n",
        "\n",
        "plot_Q(Q)\n",
        "\n",
        "Q.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02em5zORhbY4"
      },
      "source": [
        "### Exploration strategies\n",
        "1. Epsilon-greedy\n",
        "2. Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.895680Z",
          "start_time": "2019-11-07T18:54:35.859394Z"
        },
        "id": "UixpqLxNhbY6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from scipy.special import softmax\n",
        "\n",
        "seed = 42\n",
        "rg = np.random.RandomState(seed)\n",
        "\n",
        "# Epsilon greedy\n",
        "def choose_action_epsilon(Q, state, epsilon, rg=rg):\n",
        "    if (not Q[state[0], state[1]].any()) or random.random() <= epsilon: # TODO: eps greedy condition\n",
        "        return random.choice(actions) # TODO: return random action\n",
        "    else:\n",
        "        return max(actions, key = lambda action : Q[state[0]][state[1]][action])# TODO: return best action\n",
        "\n",
        "# Softmax\n",
        "def choose_action_softmax(Q, state, rg=rg):\n",
        "    tau = 5\n",
        "    action_value = Q[state[0]][state[1]]\n",
        "    max_value = action_value.max()\n",
        "    exp_values = [np.exp((v-max_value) / tau) for v in action_value]\n",
        "    normalizer = np.sum(exp_values)\n",
        "    prob = [v/normalizer for v in exp_values]\n",
        "    action = np.random.choice(actions, p=prob)\n",
        "    return action # TODO: return random action with selection probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkzBJ_pjhbY6"
      },
      "source": [
        "## SARSA\n",
        "Now we implement the SARSA algorithm.\n",
        "\n",
        "Recall the update rule for SARSA:\n",
        "\\begin{equation}\n",
        "Q(s_t,a_t) \\leftarrow  Q(s_t, a_t) + \\alpha[r_t + \\gamma Q(s_{t+1}, a_{t+1}) - Q(s_t, a_t)]\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EUo5L64hbY6"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "So we have som hyperparameters for the algorithm:\n",
        "- $\\alpha$\n",
        "- number of *episodes*.\n",
        "- $\\epsilon$: For epsilon greedy exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.904993Z",
          "start_time": "2019-11-07T18:54:35.897975Z"
        },
        "id": "1ZusJ9LqhbY6"
      },
      "outputs": [],
      "source": [
        "Q = np.zeros((env.grid.shape[0], env.grid.shape[1], len(env.action_space)))# initialize Q-value\n",
        "\n",
        "\n",
        "alpha0 = 0.4\n",
        "gamma = 0.9\n",
        "episodes = 10000\n",
        "epsilon0 = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds_tlv1lhbY7"
      },
      "source": [
        "Let's implement SARSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:54:35.917916Z",
          "start_time": "2019-11-07T18:54:35.907076Z"
        },
        "id": "JdSmq79fhbY7"
      },
      "outputs": [],
      "source": [
        "print_freq = 100\n",
        "\n",
        "def sarsa(env, Q, gamma = 0.9, plot_heat = False, choose_action = choose_action_softmax):\n",
        "\n",
        "    episode_rewards = np.zeros(episodes)\n",
        "    steps_to_completion = np.zeros(episodes)\n",
        "    if plot_heat:\n",
        "        clear_output(wait=True)\n",
        "        plot_Q(Q)\n",
        "    epsilon = epsilon0\n",
        "    alpha = alpha0\n",
        "    for ep in tqdm(range(episodes)):\n",
        "        tot_reward, steps = 0, 0\n",
        "        \n",
        "        # Reset environment\n",
        "        state = env.reset()\n",
        "        action = choose_action(Q, state)\n",
        "        done = False\n",
        "        while not done:\n",
        "            state_next, reward, done = env.step(action)\n",
        "            action_next = choose_action(Q, state_next)\n",
        "            a = state[0]\n",
        "            \n",
        "            # TODO: update equation\n",
        "            Q[state[0]][state[1]][action] = Q[state[0]][state[1]][action] + alpha *(reward + gamma * Q[state_next[0]][state_next[1]][action_next] - Q[state[0]][state[1]][action])\n",
        "                                                    \n",
        "            tot_reward += reward\n",
        "            steps += 1\n",
        "            \n",
        "            state, action = state_next, action_next\n",
        "        \n",
        "        episode_rewards[ep] = tot_reward\n",
        "        steps_to_completion[ep] = steps\n",
        "        \n",
        "        if (ep+1)%print_freq == 0 and plot_heat:\n",
        "            clear_output(wait=True)\n",
        "            plot_Q(Q, message = \"Episode %d: Reward: %f, Steps: %.2f, Qmax: %.2f, Qmin: %.2f\"%(ep+1, np.mean(episode_rewards[ep-print_freq+1:ep]),\n",
        "                                                                           np.mean(steps_to_completion[ep-print_freq+1:ep]),\n",
        "                                                                           Q.max(), Q.min()))\n",
        "                \n",
        "    return Q, episode_rewards, steps_to_completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:55:54.496385Z",
          "start_time": "2019-11-07T18:54:35.919673Z"
        },
        "id": "VGENTcWRhbY8"
      },
      "outputs": [],
      "source": [
        "Q, rewards, steps = sarsa(env, Q, gamma = gamma, plot_heat=True, choose_action= choose_action_softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD9at6PhhbY8"
      },
      "source": [
        "### Visualizing the policy\n",
        "Now let's see the agent in action.\n",
        "Run the below cell (as many times) to render the policy;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T18:56:09.771087Z",
          "start_time": "2019-11-07T18:55:54.497752Z"
        },
        "id": "pr23SK7YhbY9"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "steps = 0\n",
        "tot_reward = 0\n",
        "while not done:\n",
        "    clear_output(wait=True)\n",
        "    state, reward, done = env.step(Q[state[0], state[1]].argmax())\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    env.render(ax=plt, render_agent=True)\n",
        "    plt.show()\n",
        "    steps += 1\n",
        "    tot_reward += reward\n",
        "    sleep(0.2)\n",
        "print(\"Steps: %d, Total Reward: %d\"%(steps, tot_reward))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvGmcAe8hbY9"
      },
      "source": [
        "### Analyzing performance of the policy\n",
        "We use two metrics to analyze the policies:\n",
        "\n",
        "1. Average steps to reach the goal\n",
        "2. Total rewards from the episode\n",
        "\n",
        "To ensure, we account for randomness in environment and algorithm (say when using epsilon-greedy exploration), we run the algorithm for multiple times and use the average of values over all runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T19:05:05.323473Z",
          "start_time": "2019-11-07T18:56:09.773120Z"
        },
        "id": "cnEKA6gfhbY9"
      },
      "outputs": [],
      "source": [
        "num_expts = 5\n",
        "reward_avgs, steps_avgs = np.zeros(10000), np.zeros(10000)\n",
        "\n",
        "for i in range(num_expts):\n",
        "    print(\"Experiment: %d\"%(i+1))\n",
        "    Q = np.zeros((env.grid.shape[0], env.grid.shape[1], len(env.action_space)))\n",
        "    rg = np.random.RandomState(i)\n",
        "\n",
        "    # TODO: run sarsa, store metrics\n",
        "    Q, rewards, steps = sarsa(env, Q, gamma = gamma, plot_heat=True, choose_action= choose_action_softmax)\n",
        "    reward_avgs = reward_avgs + rewards\n",
        "    steps_avgs = steps_avgs + steps\n",
        "\n",
        "reward_avgs = reward_avgs/num_expts\n",
        "steps_avgs = steps_avgs/num_expts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-07T19:05:05.615146Z",
          "start_time": "2019-11-07T19:05:05.324664Z"
        },
        "id": "IA-KARz7hbY-"
      },
      "outputs": [],
      "source": [
        "# TODO: visualize individual metrics vs episode count (averaged across multiple run(s))\n",
        "x = np.arange(0, 10000)\n",
        "plt.figure()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Number of steps to Goal')\n",
        "plt.plot(x, steps_avgs)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.plot(x, reward_avgs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNEA4wO1hbY-"
      },
      "source": [
        "## Q-Learning\n",
        "Now, implement the Q-Learning algorithm as an exercise.\n",
        "\n",
        "Recall the update rule for Q-Learning:\n",
        "\\begin{equation}\n",
        "Q(s_t,a_t) \\leftarrow  Q(s_t, a_t) + \\alpha[r_t + \\gamma \\max_a Q(s_{t+1}, a) - Q(s_t, a_t)]\n",
        "\\end{equation}\n",
        "\n",
        "Visualize and compare results with SARSA."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Q-value\n",
        "Q = np.zeros((env.grid.shape[0], env.grid.shape[1], len(env.action_space)))\n",
        "\n",
        "alpha0 = 0.4\n",
        "gamma = 0.9\n",
        "episodes = 10000\n",
        "epsilon0 = 0.1"
      ],
      "metadata": {
        "id": "36yVW7-tnVQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_freq = 100\n",
        "\n",
        "def qlearning(env, Q, gamma = 0.9, plot_heat = False, choose_action = choose_action_softmax):\n",
        "\n",
        "    episode_rewards = np.zeros(episodes)\n",
        "    steps_to_completion = np.zeros(episodes)\n",
        "    if plot_heat:\n",
        "        clear_output(wait=True)\n",
        "        plot_Q(Q)\n",
        "    epsilon = epsilon0\n",
        "    alpha = alpha0\n",
        "    for ep in tqdm(range(episodes)):\n",
        "        tot_reward, steps = 0, 0\n",
        "        \n",
        "        # Reset environment\n",
        "        state = env.reset()\n",
        "        action = choose_action(Q, state)\n",
        "        done = False\n",
        "        while not done:\n",
        "            state_next, reward, done = env.step(action)\n",
        "            action_next = choose_action(Q, state_next)\n",
        "            \n",
        "            # TODO: update equation\n",
        "            Q[state[0]][state[1]][action] = Q[state[0]][state[1]][action] + alpha *(reward + gamma * max(Q[state_next[0]][state_next[1]]) - Q[state[0]][state[1]][action])\n",
        "                                                    \n",
        "            tot_reward += reward\n",
        "            steps += 1\n",
        "            \n",
        "            state, action = state_next, action_next\n",
        "        \n",
        "        episode_rewards[ep] = tot_reward\n",
        "        steps_to_completion[ep] = steps\n",
        "        \n",
        "        if (ep+1)%print_freq == 0 and plot_heat:\n",
        "            clear_output(wait=True)\n",
        "            plot_Q(Q, message = \"Episode %d: Reward: %f, Steps: %.2f, Qmax: %.2f, Qmin: %.2f\"%(ep+1, np.mean(episode_rewards[ep-print_freq+1:ep]),\n",
        "                                                                           np.mean(steps_to_completion[ep-print_freq+1:ep]),\n",
        "                                                                           Q.max(), Q.min()))\n",
        "                \n",
        "    return Q, episode_rewards, steps_to_completion"
      ],
      "metadata": {
        "id": "kF2YA9BpqEKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q, rewards, steps = qlearning(env, Q, gamma = gamma, plot_heat=True, choose_action= choose_action_softmax)"
      ],
      "metadata": {
        "id": "oNh7w-xaqwdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "steps = 0\n",
        "tot_reward = 0\n",
        "while not done:\n",
        "    clear_output(wait=True)\n",
        "    state, reward, done = env.step(Q[state[0], state[1]].argmax())\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    env.render(ax=plt, render_agent=True)\n",
        "    plt.show()\n",
        "    steps += 1\n",
        "    tot_reward += reward\n",
        "    sleep(0.2)\n",
        "print(\"Steps: %d, Total Reward: %d\"%(steps, tot_reward))"
      ],
      "metadata": {
        "id": "EFvrVCaNqyhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_expts = 5\n",
        "reward_avgs, steps_avgs = np.zeros(10000), np.zeros(10000)\n",
        "\n",
        "for i in range(num_expts):\n",
        "    print(\"Experiment: %d\"%(i+1))\n",
        "    Q = np.zeros((env.grid.shape[0], env.grid.shape[1], len(env.action_space)))\n",
        "    rg = np.random.RandomState(i)\n",
        "\n",
        "    # TODO: run qlearning, store metrics\n",
        "    Q, rewards, steps = qlearning(env, Q, gamma = gamma, plot_heat=True, choose_action= choose_action_softmax)\n",
        "    reward_avgs = reward_avgs + rewards\n",
        "    steps_avgs = steps_avgs + steps\n",
        "\n",
        "reward_avgs = reward_avgs/num_expts\n",
        "steps_avgs = steps_avgs/num_expts\n"
      ],
      "metadata": {
        "id": "KhsHLOwdq3tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: visualize individual metrics vs episode count (averaged across multiple run(s))\n",
        "x = np.arange(0, 10000)\n",
        "plt.figure()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Number of steps to Goal')\n",
        "plt.plot(x, steps_avgs)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.plot(x, reward_avgs)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dEEgGltlq7Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: What differences do you observe between the policies learnt by Q Learning and SARSA (if any). "
      ],
      "metadata": {
        "id": "nmmJ2LGA2IwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The differences are:\n",
        "   - Q learing seems to be taking more steps than Sarsa, but the reward obtained by both is exactly same and sometimes higher in Q learing\n",
        "   - Q learing tries to go around the red cells while Sarsa tries to get through the red walls. "
      ],
      "metadata": {
        "id": "Tm6nQB-NWxwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ],
      "metadata": {
        "id": "BzQtloO32lbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/Colab Notebooks/CS6700_Tutorial_4_QLearning_SARSA_CS22M062.ipynb\""
      ],
      "metadata": {
        "id": "J0mdbHYxz1w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afxB6g460Rl4",
        "outputId": "789db062-7660-4fe8-cd83-ae7dfeb6de2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}