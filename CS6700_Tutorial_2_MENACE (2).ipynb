{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LD5-1Iw8PafI"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from typing import NamedTuple\n","from google.colab import output"]},{"cell_type":"code","source":["SEED = 0\n","\n","BOARD_COL = 3\n","BOARD_ROW = 3\n","BOARD_SIZE = BOARD_COL * BOARD_ROW\n","\n","\"\"\"\n","Game board and actions are: {q, w, e, a, s, d, z, x, c}\n","\n","q | w | e\n","--|---|--\n","a | s | d\n","--|---|--\n","z | x | c\n","\"\"\"\n","ACTIONS_KEY_MAP = {'q': 0, 'w': 1, 'e': 2,\n","                   'a': 3, 's': 4, 'd': 5,\n","                   'z': 6, 'x': 7, 'c': 8}"],"metadata":{"id":"I04JDLKvQwPo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.random.seed(SEED)"],"metadata":{"id":"n7lTbDhBy5Of"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### State Defination"],"metadata":{"id":"UQhLYLOByy-D"}},{"cell_type":"code","source":["def print_state(board, clear_output=False):\n","  if clear_output:\n","    output.clear()\n","  for i in range(BOARD_ROW):\n","    print('-------------')\n","    out = '| '\n","    for j in range(BOARD_COL):\n","      if board[i, j] == 1:\n","          token = 'x'\n","      elif board[i, j] == -1:\n","          token = 'o'\n","      else:\n","          token = ' '  # empty position\n","      out += token + ' | '\n","    print(out)\n","  print('-------------')\n","\n","\n","class State:\n","  def __init__(self, symbol):\n","    # the board is represented by an n * n array,\n","    #  1 represents the player who moves first,\n","    # -1 represents another player\n","    #  0 represents an empty position\n","    self.board = np.zeros((BOARD_ROW, BOARD_COL))\n","    self.symbol = symbol\n","    self.winner = 0\n","    self.end = None\n","\n","  @property\n","  def hash_value(self):\n","    hash = 0\n","    for x in np.nditer(self.board):\n","      hash = 3*hash + x + 1   # unique hash\n","    return hash\n","\n","  def next(self, action: str):\n","    id = ACTIONS_KEY_MAP[action]\n","    i, j = id // BOARD_COL, id % BOARD_COL\n","    return self.next_by_pos(i, j)\n","\n","  def next_by_pos(self, i: int, j: int):\n","    assert self.board[i, j] == 0\n","    new_state = State(-self.symbol)      # another player turn\n","    new_state.board = np.copy(self.board)\n","    new_state.board[i, j] = self.symbol  # current player choose to play at (i, j) pos\n","    return new_state\n","\n","  @property\n","  def possible_actions(self):\n","    rev_action_map = {id: key for key, id in ACTIONS_KEY_MAP.items()}\n","    actions = []\n","    for i in range(BOARD_ROW):\n","      for j in range(BOARD_COL):\n","        if self.board[i, j] == 0:\n","          actions.append(rev_action_map[BOARD_COL*i+j])\n","    return actions\n","\n","  def is_end(self):\n","    if self.end is not None:\n","      return self.end\n","\n","    check = []\n","    # check row\n","    for i in range(BOARD_ROW):\n","      check.append(sum(self.board[i, :]))\n","\n","    # check col\n","    for i in range(BOARD_COL):\n","      check.append(sum(self.board[:, i]))\n","\n","    # check diagonal\n","    diagonal = 0; reverse_diagonal = 0\n","    for i in range(BOARD_ROW):\n","      diagonal += self.board[i, i]\n","      reverse_diagonal += self.board[BOARD_ROW-i-1, i]\n","    check.append(diagonal)\n","    check.append(reverse_diagonal)\n","\n","    for x in check:\n","      if x == 3:\n","        self.end = True\n","        self.winner = 1   # player 1 wins\n","        return self.end\n","      elif x == -3:\n","        self.end = True\n","        self.winner = 2   # player 2 wins\n","        return self.end\n","\n","    for x in np.nditer(self.board):\n","      if x == 0:          # play available\n","        self.end = False\n","        return self.end\n","\n","    self.winner = 0       # draw\n","    self.end = True\n","    return self.end"],"metadata":{"id":"IFBWExhtRAMR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Environment"],"metadata":{"id":"ihwyqTpPy2H2"}},{"cell_type":"code","source":["class Env:\n","  def __init__(self):\n","    self.all_states = self.get_all_states()\n","    self.curr_state = State(symbol=1)\n","\n","  def get_all_states(self):\n","    all_states = {}  # is a dict with key as state_hash_value and value as State object.\n","    def explore_all_substates(state):\n","      for i in range(BOARD_ROW):\n","        for j in range(BOARD_COL):\n","          if state.board[i, j] == 0:\n","            next_state = state.next_by_pos(i, j)\n","            if next_state.hash_value not in all_states:\n","              all_states[next_state.hash_value] = next_state\n","              if not next_state.is_end():\n","                explore_all_substates(next_state)\n","    curr_state = State(symbol=1)\n","    all_states[curr_state.hash_value] = curr_state\n","    explore_all_substates(curr_state)\n","    return all_states\n","\n","  def reset(self):\n","    self.curr_state = State(symbol=1)\n","    return self.curr_state\n","\n","  def step(self, action):\n","    assert action in self.curr_state.possible_actions, f\"Invalid {action} for the current state \\n{self.curr_state.print_state()}\"\n","    next_state_hash = self.curr_state.next(action).hash_value\n","    next_state = self.all_states[next_state_hash]\n","    self.curr_state = next_state\n","    reward = 0\n","    return self.curr_state, reward\n","\n","  def is_end(self):\n","    return self.curr_state.is_end()\n","\n","  @property\n","  def winner(self):\n","    result_id = self.curr_state.winner\n","    result = 'draw'\n","    if result_id == 1:\n","      result = 'player1'\n","    elif result_id == 2:\n","      result = 'player2'\n","    return result"],"metadata":{"id":"XJG-IRKIDsz9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Policy"],"metadata":{"id":"tZKfXapCzHNq"}},{"cell_type":"code","source":["class BasePolicy:\n","  def reset(self):\n","    pass\n","\n","  def update_values(self, *args):\n","    pass\n","\n","  def select_action(self, state):\n","    raise Exception('Not Implemented Error')"],"metadata":{"id":"pN3u_Ss0lf88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HumanPolicy(BasePolicy):\n","  def __init__(self, symbol):\n","    self.symbol = symbol\n","\n","  def select_action(self, state):\n","    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n","    print_state(state.board, clear_output=True)\n","    key = input(\"Input your position: \")\n","    return key"],"metadata":{"id":"OfddswzCRK8p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RandomPolicy(BasePolicy):\n","  def __init__(self, symbol):\n","    self.symbol = symbol\n","\n","  def select_action(self, state):\n","    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n","    return np.random.choice(state.possible_actions)"],"metadata":{"id":"kJ_18UpiogzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ActionPlayed(NamedTuple):\n","  hash_value: str\n","  action: str\n","\n","\n","class MenacePolicy(BasePolicy):\n","  def __init__(self, all_states, symbol, tau=5.0):\n","    self.all_states = all_states\n","    self.symbol = symbol\n","    self.tau = tau\n","\n","    # It store the number of stones for each action for each state\n","    self.state_action_value = self.initialize()\n","    # variable to store the history for updating the number of stones     \n","    self.history = []\n","\n","  def initialize(self):\n","    state_action_value = {}\n","    for hash_value, state in self.all_states.items():\n","      # initially all actions have 0 stones\n","      state_action_value[hash_value] = {action: 0 for action in state.possible_actions}\n","    return state_action_value\n","\n","  def reset(self):\n","    for action_value in self.state_action_value.values():\n","      for action in action_value.keys():\n","        action_value[action] = 0\n","\n","  def print_updates(self, reward):\n","    print(f'Player with symbol {self.symbol} updates the following history with {reward} stone')\n","    for item in self.history:\n","      board = np.copy(self.all_states[item.hash_value].board)\n","      id = ACTIONS_KEY_MAP[item.action]\n","      i, j = id//BOARD_COL, id%BOARD_COL\n","      board[i, j] = self.symbol\n","      print_state(board)\n","\n","  def update_values(self, reward, show_update=False):\n","    # reward: if wins receive reward of 1 stone for the chosen action\n","    #         else -1 stone.\n","    # reward is either 1 or -1 depending upon if the player has won or lost the game.\n","\n","    if show_update:\n","      self.print_updates(reward)\n","    for item in self.history:\n","\n","      # your code here\n","      self.state_action_value[item.hash_value][item.action] += reward # update state_action with appropriate term.\n","    \n","    self.history = []\n","  \n","  def select_action(self, state):  # Softmax action probability\n","    assert state.symbol == self.symbol, f\"Its not {self.symbol} symbol's turn\"\n","    action_value = self.state_action_value[state.hash_value]\n","    max_value = action_value[max(action_value, key=action_value.get)]\n","    exp_values = {action: np.exp((v-max_value) / self.tau) for action, v in action_value.items()}\n","    normalizer = np.sum([v for v in exp_values.values()])\n","    prob = {action: v/normalizer for action, v in exp_values.items()}\n","    action = np.random.choice(list(prob.keys()), p=list(prob.values()))\n","    self.history.append(ActionPlayed(state.hash_value, action))\n","    return action"],"metadata":{"id":"mos8O8H1RFe5","executionInfo":{"status":"error","timestamp":1676716561207,"user_tz":-330,"elapsed":38,"user":{"displayName":"Pankaj Singh Rawat cs22m062","userId":"01161949161099492898"}},"outputId":"c8f8582f-e8a2-4a88-8e06-eae1f386359b","colab":{"base_uri":"https://localhost:8080/","height":235}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-90fbfab7b42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mActionPlayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNamedTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mhash_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'NamedTuple' is not defined"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMCsyotNugXY","executionInfo":{"status":"ok","timestamp":1676743976340,"user_tz":-330,"elapsed":31611,"user":{"displayName":"Pankaj Singh Rawat cs22m062","userId":"01161949161099492898"}},"outputId":"60736a89-523e-47e6-a1ac-7e3c74ad6540"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### Game Board"],"metadata":{"id":"2MvkDRmozqWM"}},{"cell_type":"code","source":["class Game:\n","  def __init__(self, env, player1, player2):\n","    self.env = env\n","    self.player1 = player1\n","    self.player2 = player2\n","    self.show_updates = False\n","\n","  def alternate(self):\n","    while True:\n","      yield self.player1\n","      yield self.player2\n","\n","  def train(self, epochs=1_00_000):\n","    game_results = []\n","    player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n","    for _ in range(epochs):\n","      result = self.play()\n","\n","      # if player1 wins add 1 stone for the action chosen \n","      player1_reward = player1_reward_map[result]\n","      player2_reward = -player1_reward   # if player2 wins add 1 stone\n","\n","      self.player1.update_values(player1_reward)\n","      self.player2.update_values(player2_reward)\n","\n","  def play(self):\n","    alternate = self.alternate()\n","    state = self.env.reset()\n","    while not self.env.is_end():\n","      player = next(alternate)\n","      action = player.select_action(state)\n","      state, _ = self.env.step(action)\n","    result = self.env.winner\n","    return result"],"metadata":{"id":"qzO3FQJcCqpJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Experiment"],"metadata":{"id":"X-gqpWkKztLm"}},{"cell_type":"code","source":["env = Env()\n","\n","player1 = MenacePolicy(env.all_states, symbol=1)\n","player2 = MenacePolicy(env.all_states, symbol=-1)\n","# player2 = RandomPolicy(symbol=-1)"],"metadata":{"id":"Pr62H-hLLYdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["game = Game(env, player1, player2)\n","game.train(epochs=1_00_000)"],"metadata":{"id":"O0d23Pz5SR_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["game_with_human_player = Game(env, player1, HumanPolicy(symbol=-1))\n","\n","game_with_human_player.play()\n","\n","result = env.winner\n","print(f\"winner: {result}\")\n","\n","player1_reward_map = {'player1': 1, 'player2': -1, 'draw': 0}\n","player1.update_values(player1_reward_map[result], show_update=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMbqaln6TDXZ","outputId":"2bf96ee8-90bb-4738-d9a7-fc632e497c21","executionInfo":{"status":"ok","timestamp":1676042069597,"user_tz":-330,"elapsed":250877,"user":{"displayName":"Pankaj Singh Rawat cs22m062","userId":"01161949161099492898"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------\n","|   | o | x | \n","-------------\n","|   | x | x | \n","-------------\n","| o |   |   | \n","-------------\n","Input your position: c\n","winner: player1\n","Player with symbol 1 updates the following history with 1 stone\n","-------------\n","|   |   | x | \n","-------------\n","|   |   |   | \n","-------------\n","|   |   |   | \n","-------------\n","-------------\n","|   | o | x | \n","-------------\n","|   | x |   | \n","-------------\n","|   |   |   | \n","-------------\n","-------------\n","|   | o | x | \n","-------------\n","|   | x | x | \n","-------------\n","| o |   |   | \n","-------------\n","-------------\n","|   | o | x | \n","-------------\n","| x | x | x | \n","-------------\n","| o |   | o | \n","-------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"j4Snzpex07LF"},"execution_count":null,"outputs":[]}]}